{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34447732",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ugot import ugot\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "got = ugot.UGOT()\n",
    "got.initialize(\"192.168.1.217\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a209a4cd",
   "metadata": {},
   "source": [
    "Download https://storage.googleapis.com/mediapipe-models/object_detector/efficientdet_lite0/int8/1/efficientdet_lite0.tflite into the same folder as the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c43e7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mediapipe --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c0427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation utils\n",
    "MARGIN = 10  # pixels\n",
    "ROW_SIZE = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "TEXT_COLOR = (255, 0, 0)  # red\n",
    "\n",
    "\n",
    "def visualize(\n",
    "    image,\n",
    "    detection_result\n",
    ") -> np.ndarray:\n",
    "  \"\"\"Draws bounding boxes on the input image and return it.\n",
    "  Args:\n",
    "    image: The input RGB image.\n",
    "    detection_result: The list of all \"Detection\" entities to be visualize.\n",
    "  Returns:\n",
    "    Image with bounding boxes.\n",
    "  \"\"\"\n",
    "  for detection in detection_result.detections:\n",
    "    # Draw bounding_box\n",
    "    bbox = detection.bounding_box\n",
    "    start_point = bbox.origin_x, bbox.origin_y\n",
    "    end_point = bbox.origin_x + bbox.width, bbox.origin_y + bbox.height\n",
    "    cv2.rectangle(image, start_point, end_point, TEXT_COLOR, 3)\n",
    "\n",
    "    # Draw label and score\n",
    "    category = detection.categories[0]\n",
    "    category_name = category.category_name\n",
    "    probability = round(category.score, 2)\n",
    "    result_text = category_name + ' (' + str(probability) + ')'\n",
    "    text_location = (MARGIN + bbox.origin_x,\n",
    "                     MARGIN + ROW_SIZE + bbox.origin_y)\n",
    "    cv2.putText(image, result_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                FONT_SIZE, TEXT_COLOR, FONT_THICKNESS)\n",
    "\n",
    "  return image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce91d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "\n",
    "\n",
    "def run(model: str) -> None:\n",
    "  \"\"\"Continuously run inference on images acquired from the camera.\n",
    "\n",
    "  Args:\n",
    "    model: Name of the TFLite object detection model.\n",
    "    camera_id: The camera id to be passed to OpenCV.\n",
    "    width: The width of the frame captured from the camera.\n",
    "    height: The height of the frame captured from the camera.\n",
    "  \"\"\"\n",
    "\n",
    "  # Variables to calculate FPS\n",
    "  counter, fps = 0, 0\n",
    "  start_time = time.time()\n",
    "\n",
    "  # Start capturing video input from the camera\n",
    "#   cap = cv2.VideoCapture(camera_id)\n",
    "#   cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "#   cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "\n",
    "  # Visualization parameters\n",
    "  row_size = 20  # pixels\n",
    "  left_margin = 24  # pixels\n",
    "  text_color = (0, 0, 255)  # red\n",
    "  font_size = 1\n",
    "  font_thickness = 1\n",
    "  fps_avg_frame_count = 10\n",
    "\n",
    "  detection_result_list = []\n",
    "\n",
    "  def visualize_callback(result: vision.ObjectDetectorResult,\n",
    "                         output_image: mp.Image, timestamp_ms: int):\n",
    "      result.timestamp_ms = timestamp_ms\n",
    "      detection_result_list.append(result)\n",
    "\n",
    "\n",
    "  # Initialize the object detection model\n",
    "  base_options = python.BaseOptions(model_asset_path=model)\n",
    "  options = vision.ObjectDetectorOptions(base_options=base_options,\n",
    "                                         running_mode=vision.RunningMode.LIVE_STREAM,\n",
    "                                         score_threshold=0.5,\n",
    "                                         result_callback=visualize_callback)\n",
    "  detector = vision.ObjectDetector.create_from_options(options)\n",
    "\n",
    "  got.open_camera()\n",
    "  # Continuously capture images from the camera and run inference\n",
    "  while True:\n",
    "    frame = got.read_camera_data()\n",
    "    if not frame:\n",
    "        break\n",
    "    nparr = np.frombuffer(frame, np.uint8)\n",
    "    frame = cv2.imdecode(nparr, cv2.IMREAD_COLOR)\n",
    "\n",
    "    counter += 1\n",
    "    # image = cv2.flip(frame, 1)\n",
    "\n",
    "    # Convert the image from BGR to RGB as required by the TFLite model.\n",
    "    rgb_image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb_image)\n",
    "\n",
    "    # Run object detection using the model.\n",
    "    detector.detect_async(mp_image, counter)\n",
    "    current_frame = mp_image.numpy_view()\n",
    "    current_frame = cv2.cvtColor(current_frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    # Calculate the FPS\n",
    "    if counter % fps_avg_frame_count == 0:\n",
    "        end_time = time.time()\n",
    "        fps = fps_avg_frame_count / (end_time - start_time)\n",
    "        start_time = time.time()\n",
    "\n",
    "    # Show the FPS\n",
    "    fps_text = 'FPS = {:.1f}'.format(fps)\n",
    "    text_location = (left_margin, row_size)\n",
    "    cv2.putText(current_frame, fps_text, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                font_size, text_color, font_thickness)\n",
    "\n",
    "    if detection_result_list:\n",
    "        clear_output(wait=True)\n",
    "        print(detection_result_list)\n",
    "        vis_image = visualize(current_frame, detection_result_list[0])\n",
    "        cv2.imshow('object_detector', vis_image)\n",
    "        detection_result_list.clear()\n",
    "    else:\n",
    "        cv2.imshow('object_detector', current_frame)\n",
    "\n",
    "    # Stop the program if the ESC key is pressed.\n",
    "    if cv2.waitKey(1) == 27:\n",
    "      break\n",
    "\n",
    "  detector.close()\n",
    "  # cap.release()\n",
    "  cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "run(\"efficientdet_lite0.tflite\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
